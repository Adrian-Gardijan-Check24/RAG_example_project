{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports und Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# IMPORTANT add your api key here\n",
    "api_key = \"your-api-key\"\n",
    "\n",
    "\n",
    "# website of the check24 Tippspiel Teilnahmebedingungen\n",
    "website_url = \"https://tippspiel.check24.de/ul/champions-league-24-25/teilnahmebedingungen\"\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=api_key)\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohappyeyeballs==2.4.4\n",
      "aiohttp==3.11.11\n",
      "aiosignal==1.3.2\n",
      "annotated-types==0.7.0\n",
      "anyio==4.8.0\n",
      "appnope==0.1.4\n",
      "asgiref==3.8.1\n",
      "asttokens==3.0.0\n",
      "attrs==25.1.0\n",
      "backoff==2.2.1\n",
      "bcrypt==4.2.1\n",
      "beautifulsoup4==4.13.3\n",
      "blinker==1.9.0\n",
      "bs4==0.0.2\n",
      "build==1.2.2.post1\n",
      "cachetools==5.5.1\n",
      "certifi==2025.1.31\n",
      "charset-normalizer==3.4.1\n",
      "chroma-hnswlib==0.7.6\n",
      "chromadb==0.6.3\n",
      "click==8.1.8\n",
      "coloredlogs==15.0.1\n",
      "comm==0.2.2\n",
      "contourpy==1.3.1\n",
      "cycler==0.12.1\n",
      "dash==2.18.2\n",
      "dash-core-components==2.0.0\n",
      "dash-html-components==2.0.0\n",
      "dash-table==5.0.0\n",
      "dataclasses-json==0.6.7\n",
      "debugpy==1.8.12\n",
      "decorator==5.1.1\n",
      "Deprecated==1.2.18\n",
      "distro==1.9.0\n",
      "durationpy==0.9\n",
      "executing==2.2.0\n",
      "faiss-cpu==1.10.0\n",
      "fastapi==0.115.8\n",
      "fastjsonschema==2.21.1\n",
      "filelock==3.17.0\n",
      "Flask==3.0.3\n",
      "flatbuffers==25.1.24\n",
      "fonttools==4.55.8\n",
      "frozenlist==1.5.0\n",
      "fsspec==2025.2.0\n",
      "google-auth==2.38.0\n",
      "googleapis-common-protos==1.66.0\n",
      "grpcio==1.70.0\n",
      "h11==0.14.0\n",
      "httpcore==1.0.7\n",
      "httptools==0.6.4\n",
      "httpx==0.28.1\n",
      "httpx-sse==0.4.0\n",
      "huggingface-hub==0.28.1\n",
      "humanfriendly==10.0\n",
      "idna==3.10\n",
      "importlib_metadata==8.5.0\n",
      "importlib_resources==6.5.2\n",
      "ipykernel==6.29.5\n",
      "ipython==8.32.0\n",
      "itsdangerous==2.2.0\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.5\n",
      "jiter==0.8.2\n",
      "joblib==1.4.2\n",
      "jsonpatch==1.33\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "kiwisolver==1.4.8\n",
      "kubernetes==32.0.0\n",
      "langchain==0.3.17\n",
      "langchain-community==0.3.16\n",
      "langchain-core==0.3.33\n",
      "langchain-openai==0.3.3\n",
      "langchain-text-splitters==0.3.5\n",
      "langsmith==0.3.4\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "marshmallow==3.26.1\n",
      "matplotlib==3.10.0\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mmh3==5.1.0\n",
      "monotonic==1.6\n",
      "mpmath==1.3.0\n",
      "multidict==6.1.0\n",
      "mypy-extensions==1.0.0\n",
      "narwhals==1.25.2\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "numpy==2.2.2\n",
      "oauthlib==3.2.2\n",
      "onnxruntime==1.20.1\n",
      "openai==1.61.1\n",
      "opentelemetry-api==1.30.0\n",
      "opentelemetry-exporter-otlp-proto-common==1.30.0\n",
      "opentelemetry-exporter-otlp-proto-grpc==1.30.0\n",
      "opentelemetry-instrumentation==0.51b0\n",
      "opentelemetry-instrumentation-asgi==0.51b0\n",
      "opentelemetry-instrumentation-fastapi==0.51b0\n",
      "opentelemetry-proto==1.30.0\n",
      "opentelemetry-sdk==1.30.0\n",
      "opentelemetry-semantic-conventions==0.51b0\n",
      "opentelemetry-util-http==0.51b0\n",
      "orjson==3.10.15\n",
      "overrides==7.7.0\n",
      "packaging==24.2\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "pexpect==4.9.0\n",
      "pillow==11.1.0\n",
      "platformdirs==4.3.6\n",
      "plotly==6.0.0\n",
      "posthog==3.11.0\n",
      "prompt_toolkit==3.0.50\n",
      "propcache==0.2.1\n",
      "protobuf==5.29.3\n",
      "psutil==6.1.1\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.3\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.1\n",
      "pydantic==2.10.6\n",
      "pydantic-settings==2.7.1\n",
      "pydantic_core==2.27.2\n",
      "Pygments==2.19.1\n",
      "pyparsing==3.2.1\n",
      "PyPika==0.48.9\n",
      "pyproject_hooks==1.2.0\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "pytz==2025.1\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.2.1\n",
      "referencing==0.36.2\n",
      "regex==2024.11.6\n",
      "requests==2.32.3\n",
      "requests-oauthlib==2.0.0\n",
      "requests-toolbelt==1.0.0\n",
      "retrying==1.3.4\n",
      "rich==13.9.4\n",
      "rpds-py==0.22.3\n",
      "rsa==4.9\n",
      "scikit-learn==1.6.1\n",
      "scipy==1.15.1\n",
      "setuptools==75.8.0\n",
      "shellingham==1.5.4\n",
      "six==1.17.0\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.6\n",
      "SQLAlchemy==2.0.37\n",
      "stack-data==0.6.3\n",
      "starlette==0.45.3\n",
      "sympy==1.13.3\n",
      "tenacity==9.0.0\n",
      "threadpoolctl==3.5.0\n",
      "tiktoken==0.8.0\n",
      "tokenizers==0.21.0\n",
      "tornado==6.4.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "typer==0.15.1\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2025.1\n",
      "urllib3==2.3.0\n",
      "uvicorn==0.34.0\n",
      "uvloop==0.21.0\n",
      "watchfiles==1.0.4\n",
      "wcwidth==0.2.13\n",
      "websocket-client==1.8.0\n",
      "websockets==14.2\n",
      "Werkzeug==3.0.6\n",
      "wrapt==1.17.2\n",
      "yarl==1.18.3\n",
      "zipp==3.21.0\n",
      "zstandard==0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websitetext einlesen und für Embedding vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_website(url):\n",
    "    # read the text from the website\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "\n",
    "    # remove unwanted tags\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    for tag in soup.select(\"nav, footer, .c24-cookie-consent-notice, .ads, .sidebar\"):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\"\\n\")  # Extract text while keeping structure\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cookies_info(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    cookies_over = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == \"Alle akzeptieren\": #search for end of cookie info which appears at beginning of scraped text\n",
    "            cookies_over = True\n",
    "        if cookies_over:\n",
    "            cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def remove_empty_lines(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def remove_urls(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    skip_next = 0\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if i < len(lines) - 2 and (lines[i+1][0:4] == \"http\" or lines[i+1] == \"hier\" or lines[i+1] == \"Link\" ): # skip urls and remove corresponding line brakes\n",
    "            skip_next = 3\n",
    "            cleaned_lines.append(lines[i] + lines[i+2])\n",
    "        if skip_next > 0:\n",
    "            skip_next -= 1\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "def remove_top_level_headers(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        # Skip first two lines (they only contain headers etc)\n",
    "        if i < 2:\n",
    "            continue\n",
    "\n",
    "        # Detect a top-level section header (e.g., \"3\") followed by a short title\n",
    "        if re.match(r\"^\\d+$\", lines[i].strip()) and i + 1 < len(lines):\n",
    "            continue  # Do not include the number\n",
    "        elif re.match(r\"^\\d+$\", lines[i - 1].strip()):\n",
    "            continue  # Skip title (line after number)\n",
    "\n",
    "        # Add the rest of the content\n",
    "        cleaned_lines.append(lines[i])\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "def propagate_parent_sections(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Propagates parent sections to their respective child sections in a given text.\n",
    "    This function processes a text where sections are denoted by hierarchical numbering (e.g., \"4.2.\", \"4.2.1.\", \"4.2.1.1.\").\n",
    "    It appends the parent section titles to their respective child sections to provide context.\n",
    "    Args:\n",
    "        text (str): The input text containing sections and sub-sections.\n",
    "    Returns:\n",
    "        str: The processed text with parent sections propagated to their child sections.\n",
    "    \"\"\"\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    current_parent = \"\"\n",
    "    current_child = \"\"\n",
    "    parent_coming = False\n",
    "    child_coming = False\n",
    "    childchild_coming = False\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        if parent_coming:\n",
    "            current_parent = stripped\n",
    "            parent_coming = False\n",
    "\n",
    "        if child_coming:\n",
    "            current_child = stripped\n",
    "            cleaned_lines.append(current_parent + \" \" + line)\n",
    "            child_coming = False\n",
    "        elif childchild_coming:\n",
    "            cleaned_lines.append(current_parent + \" \" + current_child + \" \" + line)\n",
    "            childchild_coming = False\n",
    "        else:\n",
    "            cleaned_lines.append(line)\n",
    "        \n",
    "        # Detect major section (e.g., \"4.2.\") but NOT \"4.2.1.\"\n",
    "        if re.match(r\"^\\d+\\.\\d+\\.$\", stripped):\n",
    "            parent_coming = True\n",
    "        \n",
    "        # Detect sub-sections (e.g., \"4.2.1.\") but not top-level sections\n",
    "        elif re.match(r\"^\\d+\\.\\d+\\.\\d+\\.$\", stripped):\n",
    "            child_coming = True\n",
    "\n",
    "            # Detect sub-sections (e.g., \"4.2.1.\") but not top-level sections\n",
    "        elif re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+\\.$\", stripped):\n",
    "            childchild_coming = True\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\d+\\.\\d+\\.$\", line) or re.match(r\"^\\d+\\.\\d+\\.\\d+\\.$\", line) or re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+\\.$\", line):\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text from the website\n",
    "text = read_website(website_url)\n",
    "\n",
    "# Preprocess the text by removing unnecessary information and improving formatting\n",
    "text = remove_empty_lines(text)\n",
    "text = remove_cookies_info(text)\n",
    "text = remove_urls(text)\n",
    "text = remove_top_level_headers(text)\n",
    "text = propagate_parent_sections(text)\n",
    "text = remove_numbers(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text in Chunks aufteilen und Embedding-Vectors berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete! Stored 70 chunks in FAISS.\n"
     ]
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "# Generate embeddings using OpenAI\n",
    "embeddings = embedding_model.embed_documents(chunks)\n",
    "\n",
    "# Convert to FAISS format with euclidian (L2) distance measure for similarity search\n",
    "dimension = len(embeddings[0])  # Get embedding size\n",
    "faiss_index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
    "faiss_index.add(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "# Store chunk text with same indices as in \n",
    "chunk_metadata = {i: chunks[i] for i in range(len(chunks))}\n",
    "\n",
    "print(\"Vectorization complete! Stored\", len(chunks), \"chunks in FAISS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für Prompt relevanteste Chunks heraussuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query, number_of_chunks_to_retrieve=5):\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "    # Search for similar chunks\n",
    "    _, similar_indices = faiss_index.search(np.array([query_embedding], dtype=np.float32), \n",
    "                                            number_of_chunks_to_retrieve)\n",
    "\n",
    "    # Get the text of the similar chunks\n",
    "    similar_chunks = [chunk_metadata[i] for i in similar_indices[0]]\n",
    "\n",
    "    return similar_chunks, similar_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modell Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompt):\n",
    "    answer = \"\"\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True, \n",
    "    )\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            answer += chunk.choices[0].delta.content\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage:\n",
      " Was kann ich gewinnen?\n",
      "\n",
      "Kontext wird gesucht...\n",
      "\n",
      "Kontext 1:\n",
      "Gutscheine aus der Gesamtwertung und den jeweiligen Spieltagen im Wert von 240 € (in Worten zweihundertvierzig) und weniger werden passend zur Gewinneranzahl aufgestockt, damit jeder mit entsprechender Platzierung einen Gutschein erhält.\n",
      "Für die zu gewinnenden Gutscheine gelten die folgenden separaten Gutscheinbedingungen der CHECK24 GmbH ().\n",
      "Ein Anspruch auf Barauszahlung eines Gewinnes (nach Ziffer 4) besteht seitens des Gewinners nicht.\n",
      "Kontext 2:\n",
      "In der Gesamtwertung der CHECK24 Tipprunde vergibt der Veranstalter für die Nutzer mit den meisten Punkten (gem. Ziffer 2) die folgenden Gewinne:\n",
      "1 x 2.400 € Reise-Guthaben\n",
      "Zusätzlich gibt es mehrere vom Veranstalter definierte Spieltage. Ein Spieltag bezeichnet einen festgelegten Termin, an dem eine Runde von Spielen innerhalb des Wettbewerbs, wie in der Gruppenphase oder K.-o.-Runde, ausgetragen wird. An einem Spieltag finden mehrere Spiele gleichzeitig statt.\n",
      "Kontext 3:\n",
      "24 x 10 % Hotel- & Ferienwohnungs-Gutschein\n",
      "In der teilnahmeberechtigten Tipprunden (nach der Ziffer 4.2.) vergibt der Veranstalter zudem die folgenden Gewinne:\n",
      "Für die beste Tipprunde, nach der Durchschnittspunktzahl (gem. Ziffer 2) und nach Ende der Ligaphase (29.01.2025) gewertet:\n",
      "11 Tickets für das Finale der \n",
      "Königsklasse\n",
      " in München\n",
      "Kontext 4:\n",
      "in München\n",
      "Sollte der Verdacht vorliegen, dass Mitglieder der Tipprunden Ihre Tipps untereinander abgestimmt hätten, behält sich der Betreiber vor, Tipprunden von diesem Preis auszuschließen.\n",
      "Für die jeweiligen Nutzer in den teilnahmeberechtigten Tipprunden mit den meisten Punkten nach Abschluss (gem. Ziffer 2), den „Tipprundensiegern“:\n",
      "2000 x 240 € Pauschalreise-Gutscheine (einlösbar ab 2.400 € Buchungswert (exkl. lokaler Steuern, wie z.B. Touristensteuer))\n",
      "Kontext 5:\n",
      "Pro Spieltag werden folgende Gewinne für die Teilnehmer mit den höchsten erreichten Punkten (nach Ziffer 2) der jeweiligen Spieltage vergeben:\n",
      "24 x 240 € Pauschalreise-Gutscheine (einlösbar ab 2.400 € Buchungswert (exkl. lokaler Steuern, wie z.B. Touristensteuer))\n",
      "Pro Spieltag werden folgende Gewinne für alle Mitglieder der besten teilnahmeberechtigten Tipprunden (nach der Ziffer 4.2.), gemessen nach Durchschnittspunktzahl für den jeweiligen Spieltag:\n",
      "24 x 10 % Hotel- & Ferienwohnungs-Gutschein\n",
      "\n",
      "Antwort wird generiert...\n",
      "\n",
      "Antwort:\n",
      " Bei dem Gewinnspiel hast du die Möglichkeit, folgende Preise zu gewinnen:\n",
      "\n",
      "1. **Gesamtwertung der CHECK24 Tipprunde:**\n",
      "   - 1 x 2.400 € Reise-Guthaben für den Benutzer mit den meisten Punkten.\n",
      "\n",
      "2. **Gewinne pro Spieltag:**\n",
      "   - 24 x 240 € Pauschalreise-Gutscheine, einlösbar ab einem Buchungswert von 2.400 € (exklusive lokaler Steuern).\n",
      "   - 24 x 10 % Hotel- & Ferienwohnungs-Gutschein.\n",
      "\n",
      "3. **Beste Tipprunde nach der Ligaphase (bis 29.01.2025):**\n",
      "   - 11 Tickets für das Finale der Königsklasse in München.\n",
      "\n",
      "4. **Tipprundensieger in den teilnahmeberechtigten Tipprunden:**\n",
      "   - 2.000 x 240 € Pauschalreise-Gutscheine, einlösbar ab einem Buchungswert von 2.400 € (exklusive lokaler Steuern).\n",
      "\n",
      "Bitte beachte, dass ein Anspruch auf Barauszahlung eines Gewinnes nicht besteht und die Bedingungen des Gewinnspiels beachtet werden müssen.\n"
     ]
    }
   ],
   "source": [
    "# Hier eine Frage zu den Teilnahmebedingungen eingeben um das Modell zu testen\n",
    "query = \"Was kann ich gewinnen?\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Frage:\\n\", query)\n",
    "\n",
    "\n",
    "# Get context\n",
    "print(\"\\nKontext wird gesucht...\\n\")\n",
    "\n",
    "context_chunks, _ = get_context(query, number_of_chunks_to_retrieve=5)\n",
    "\n",
    "print(\"\\n\".join([\"Kontext \" + str(i + 1) + \":\\n\" + context for i, context in enumerate(context_chunks)]))\n",
    "\n",
    "context = \"\\n\".join(context_chunks) # Combine chunks into one string\n",
    "\n",
    "\n",
    "# Create final prompt\n",
    "print(\"\\nAntwort wird generiert...\\n\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Du bist ein KI-Assistent, der Fragen zu den Teilnahmebedingungen eines Gewinnspiels beantwortet. Zur Beantwortung der Frage hast du folgenden Kontext:\n",
    "\n",
    "Kontext:\n",
    "{context}\n",
    "\n",
    "Die Frage des Benutzers lautet:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "answer = get_answer(prompt)\n",
    "\n",
    "print(\"Antwort:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing PCA\n",
      "PCA done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"doing PCA\")\n",
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "print(\"PCA done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model(query):\n",
    "    context_chunks, context_indices = get_context(query, number_of_chunks_to_retrieve=5)\n",
    "    context = \"\\n\\n\".join(context_chunks) # Combine chunks into one string\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Du bist ein KI-Assistent, der Fragen zu den Teilnahmebedingungen eines Gewinnspiels beantwortet. Zur Beantwortung der Frage hast du folgenden Kontext:\n",
    "\n",
    "    Kontext:\n",
    "    {context}\n",
    "\n",
    "    Die Frage des Benutzers lautet:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    answer = get_answer(prompt)\n",
    "    return answer, context_indices, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x134545230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "# Update the layout\n",
    "layout = go.Layout(\n",
    "    hovermode='closest',\n",
    "    xaxis={'title': {'text': 'PCA Component 1'}},\n",
    "    yaxis={'title': {'text': 'PCA Component 2'}},\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Create the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"PCA of Text Chunks\", style={\"text-align\": \"center\"}),\n",
    "    \n",
    "    # Text Input for query\n",
    "    html.Div([\n",
    "        dcc.Input(id='query-input', type='text', placeholder='Enter your query here', style={'width': '80%', 'border': '1px solid black'}),\n",
    "        html.Button('Submit', id='submit-button', n_clicks=0)\n",
    "    ], style={'text-align': 'center', 'padding-top': '20px'}),\n",
    "    \n",
    "    # Model Answer\n",
    "    html.Div([\n",
    "        html.H4(\"Model Answer\"),\n",
    "        html.Div(id='model-answer', style={'white-space': 'pre-line', 'padding': '10px'})\n",
    "    ], style={'padding-top': '20px'}),\n",
    "    \n",
    "    # Plot and Text of Selected Chunk\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Graph(\n",
    "                id='scatter-plot',\n",
    "                figure={'data': [trace], 'layout': layout},\n",
    "                config={'displayModeBar': False}  # Turn off the toolbar\n",
    "            ),\n",
    "            html.Div([\n",
    "                html.H4(\"Text of Selected Chunk\"),\n",
    "                html.Div(id='chunk-text', style={'white-space': 'pre-line', 'padding': '10px'})\n",
    "            ], style={'padding-top': '20px'})\n",
    "        ], style={'width': '60%', 'display': 'inline-block', 'vertical-align': 'top', 'padding-top': '5px'}),\n",
    "        \n",
    "        # Augmented Prompt\n",
    "        html.Div([\n",
    "            html.H4(\"Augmented Prompt\"),\n",
    "            html.Div(id='augmented-prompt', style={'white-space': 'pre-line', 'padding': '10px', 'font-size': 'small'})\n",
    "        ], style={'width': '35%', 'display': 'inline-block', 'vertical-align': 'top', 'padding-left': '20px'})\n",
    "    ], style={'padding-top': '5px', 'text-align': 'left'})  # Reduced padding-top here\n",
    "])\n",
    "\n",
    "# Define callback to update the text box when a point is clicked\n",
    "@app.callback(\n",
    "    Output('chunk-text', 'children'),\n",
    "    [Input('scatter-plot', 'clickData')]\n",
    ")\n",
    "def display_chunk_text(clickData):\n",
    "    if clickData is None:\n",
    "        return \"Click on a point to see the chunk text.\"\n",
    "    \n",
    "    # Extract the index of the clicked point\n",
    "    point_index = clickData['points'][0]['pointIndex']\n",
    "    \n",
    "    # Return the text of the corresponding chunk\n",
    "    return chunks[point_index]\n",
    "\n",
    "# Define callback to update the plot with the query embedding, model answer, and augmented prompt\n",
    "@app.callback(\n",
    "    [Output('scatter-plot', 'figure'), Output('model-answer', 'children'), Output('augmented-prompt', 'children')],\n",
    "    [Input('submit-button', 'n_clicks')],\n",
    "    [State('query-input', 'value')]\n",
    ")\n",
    "def update_plot(n_clicks, query):\n",
    "    if n_clicks > 0 and query:\n",
    "        # Get the model answer, context indices, and augmented prompt\n",
    "        model_answer, context_indices, augmented_prompt = prompt_model(query)\n",
    "        \n",
    "        # Create a new trace for the query embedding\n",
    "        query_embedding = embedding_model.embed_query(query)\n",
    "        query_pca = pca.transform([query_embedding])[0]\n",
    "        query_trace = go.Scatter(\n",
    "            x=[query_pca[0]],\n",
    "            y=[query_pca[1]],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color='red', opacity=0.7),\n",
    "            text=[query],  # Add the query text to display on hover\n",
    "            hoverinfo='text',  # Enable hover info\n",
    "            name='Query'  # Add legend name\n",
    "        )\n",
    "        \n",
    "        # Separate the chunks into relevant and non-relevant\n",
    "        relevant_chunks = [i for i in range(len(chunks)) if i in context_indices]\n",
    "        non_relevant_chunks = [i for i in range(len(chunks)) if i not in context_indices]\n",
    "        \n",
    "        # Create traces for relevant and non-relevant chunks\n",
    "        relevant_trace = go.Scatter(\n",
    "            x=pca_embeddings[relevant_chunks, 0],\n",
    "            y=pca_embeddings[relevant_chunks, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color='orange', opacity=0.7),\n",
    "            text=[chunks[i] for i in relevant_chunks],\n",
    "            hoverinfo='none',\n",
    "            name='Relevant Chunks'  # Add legend name\n",
    "        )\n",
    "        \n",
    "        non_relevant_trace = go.Scatter(\n",
    "            x=pca_embeddings[non_relevant_chunks, 0],\n",
    "            y=pca_embeddings[non_relevant_chunks, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color='blue', opacity=0.7),\n",
    "            text=[chunks[i] for i in non_relevant_chunks],\n",
    "            hoverinfo='none',\n",
    "            name='Info-Chunks'  # Add legend name\n",
    "        )\n",
    "        \n",
    "        # Update the figure with the new traces\n",
    "        figure = {\n",
    "            'data': [non_relevant_trace, relevant_trace, query_trace],\n",
    "            'layout': layout\n",
    "        }\n",
    "        \n",
    "        return figure, model_answer, augmented_prompt\n",
    "    \n",
    "    # Return the original figure, empty model answer, and empty augmented prompt if no query is submitted\n",
    "    return {'data': [trace], 'layout': layout}, \"\", \"\"\n",
    "\n",
    "# Run the Dash app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash in ./.venv/lib/python3.13/site-packages (2.18.2)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in ./.venv/lib/python3.13/site-packages (from dash) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in ./.venv/lib/python3.13/site-packages (from dash) (3.0.6)\n",
      "Requirement already satisfied: plotly>=5.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (6.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.13/site-packages (from dash) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.13/site-packages (from dash) (4.12.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from dash) (2.32.3)\n",
      "Requirement already satisfied: retrying in ./.venv/lib/python3.13/site-packages (from dash) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.13/site-packages (from dash) (1.6.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from dash) (75.8.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.13/site-packages (from plotly>=5.0.0->dash) (1.25.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from plotly>=5.0.0->dash) (24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.13/site-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata->dash) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->dash) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->dash) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->dash) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->dash) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.7.0 in ./.venv/lib/python3.13/site-packages (from retrying->dash) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install dash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
