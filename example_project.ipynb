{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports und Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# IMPORTANT add your api key here\n",
    "api_key = \"your-api-key\"\n",
    "\n",
    "\n",
    "# website of the check24 Tippspiel Teilnahmebedingungen\n",
    "website_url = \"https://tippspiel.check24.de/ul/champions-league-24-25/teilnahmebedingungen\"\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=api_key)\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohappyeyeballs==2.4.4\n",
      "aiohttp==3.11.11\n",
      "aiosignal==1.3.2\n",
      "annotated-types==0.7.0\n",
      "anyio==4.8.0\n",
      "appnope==0.1.4\n",
      "asgiref==3.8.1\n",
      "asttokens==3.0.0\n",
      "attrs==25.1.0\n",
      "backoff==2.2.1\n",
      "bcrypt==4.2.1\n",
      "beautifulsoup4==4.13.3\n",
      "blinker==1.9.0\n",
      "bs4==0.0.2\n",
      "build==1.2.2.post1\n",
      "cachetools==5.5.1\n",
      "certifi==2025.1.31\n",
      "charset-normalizer==3.4.1\n",
      "chroma-hnswlib==0.7.6\n",
      "chromadb==0.6.3\n",
      "click==8.1.8\n",
      "coloredlogs==15.0.1\n",
      "comm==0.2.2\n",
      "contourpy==1.3.1\n",
      "cycler==0.12.1\n",
      "dash==2.18.2\n",
      "dash-core-components==2.0.0\n",
      "dash-html-components==2.0.0\n",
      "dash-table==5.0.0\n",
      "dataclasses-json==0.6.7\n",
      "debugpy==1.8.12\n",
      "decorator==5.1.1\n",
      "Deprecated==1.2.18\n",
      "distro==1.9.0\n",
      "durationpy==0.9\n",
      "executing==2.2.0\n",
      "faiss-cpu==1.10.0\n",
      "fastapi==0.115.8\n",
      "fastjsonschema==2.21.1\n",
      "filelock==3.17.0\n",
      "Flask==3.0.3\n",
      "flatbuffers==25.1.24\n",
      "fonttools==4.55.8\n",
      "frozenlist==1.5.0\n",
      "fsspec==2025.2.0\n",
      "google-auth==2.38.0\n",
      "googleapis-common-protos==1.66.0\n",
      "grpcio==1.70.0\n",
      "h11==0.14.0\n",
      "httpcore==1.0.7\n",
      "httptools==0.6.4\n",
      "httpx==0.28.1\n",
      "httpx-sse==0.4.0\n",
      "huggingface-hub==0.28.1\n",
      "humanfriendly==10.0\n",
      "idna==3.10\n",
      "importlib_metadata==8.5.0\n",
      "importlib_resources==6.5.2\n",
      "ipykernel==6.29.5\n",
      "ipython==8.32.0\n",
      "itsdangerous==2.2.0\n",
      "jedi==0.19.2\n",
      "Jinja2==3.1.5\n",
      "jiter==0.8.2\n",
      "joblib==1.4.2\n",
      "jsonpatch==1.33\n",
      "jsonpointer==3.0.0\n",
      "jsonschema==4.23.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jupyter_client==8.6.3\n",
      "jupyter_core==5.7.2\n",
      "kiwisolver==1.4.8\n",
      "kubernetes==32.0.0\n",
      "langchain==0.3.17\n",
      "langchain-community==0.3.16\n",
      "langchain-core==0.3.33\n",
      "langchain-openai==0.3.3\n",
      "langchain-text-splitters==0.3.5\n",
      "langsmith==0.3.4\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==3.0.2\n",
      "marshmallow==3.26.1\n",
      "matplotlib==3.10.0\n",
      "matplotlib-inline==0.1.7\n",
      "mdurl==0.1.2\n",
      "mmh3==5.1.0\n",
      "monotonic==1.6\n",
      "mpmath==1.3.0\n",
      "multidict==6.1.0\n",
      "mypy-extensions==1.0.0\n",
      "narwhals==1.25.2\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "numpy==2.2.2\n",
      "oauthlib==3.2.2\n",
      "onnxruntime==1.20.1\n",
      "openai==1.61.1\n",
      "opentelemetry-api==1.30.0\n",
      "opentelemetry-exporter-otlp-proto-common==1.30.0\n",
      "opentelemetry-exporter-otlp-proto-grpc==1.30.0\n",
      "opentelemetry-instrumentation==0.51b0\n",
      "opentelemetry-instrumentation-asgi==0.51b0\n",
      "opentelemetry-instrumentation-fastapi==0.51b0\n",
      "opentelemetry-proto==1.30.0\n",
      "opentelemetry-sdk==1.30.0\n",
      "opentelemetry-semantic-conventions==0.51b0\n",
      "opentelemetry-util-http==0.51b0\n",
      "orjson==3.10.15\n",
      "overrides==7.7.0\n",
      "packaging==24.2\n",
      "pandas==2.2.3\n",
      "parso==0.8.4\n",
      "pexpect==4.9.0\n",
      "pillow==11.1.0\n",
      "platformdirs==4.3.6\n",
      "plotly==6.0.0\n",
      "posthog==3.11.0\n",
      "prompt_toolkit==3.0.50\n",
      "propcache==0.2.1\n",
      "protobuf==5.29.3\n",
      "psutil==6.1.1\n",
      "ptyprocess==0.7.0\n",
      "pure_eval==0.2.3\n",
      "pyasn1==0.6.1\n",
      "pyasn1_modules==0.4.1\n",
      "pydantic==2.10.6\n",
      "pydantic-settings==2.7.1\n",
      "pydantic_core==2.27.2\n",
      "Pygments==2.19.1\n",
      "pyparsing==3.2.1\n",
      "PyPika==0.48.9\n",
      "pyproject_hooks==1.2.0\n",
      "python-dateutil==2.9.0.post0\n",
      "python-dotenv==1.0.1\n",
      "pytz==2025.1\n",
      "PyYAML==6.0.2\n",
      "pyzmq==26.2.1\n",
      "referencing==0.36.2\n",
      "regex==2024.11.6\n",
      "requests==2.32.3\n",
      "requests-oauthlib==2.0.0\n",
      "requests-toolbelt==1.0.0\n",
      "retrying==1.3.4\n",
      "rich==13.9.4\n",
      "rpds-py==0.22.3\n",
      "rsa==4.9\n",
      "scikit-learn==1.6.1\n",
      "scipy==1.15.1\n",
      "setuptools==75.8.0\n",
      "shellingham==1.5.4\n",
      "six==1.17.0\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.6\n",
      "SQLAlchemy==2.0.37\n",
      "stack-data==0.6.3\n",
      "starlette==0.45.3\n",
      "sympy==1.13.3\n",
      "tenacity==9.0.0\n",
      "threadpoolctl==3.5.0\n",
      "tiktoken==0.8.0\n",
      "tokenizers==0.21.0\n",
      "tornado==6.4.2\n",
      "tqdm==4.67.1\n",
      "traitlets==5.14.3\n",
      "typer==0.15.1\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.12.2\n",
      "tzdata==2025.1\n",
      "urllib3==2.3.0\n",
      "uvicorn==0.34.0\n",
      "uvloop==0.21.0\n",
      "watchfiles==1.0.4\n",
      "wcwidth==0.2.13\n",
      "websocket-client==1.8.0\n",
      "websockets==14.2\n",
      "Werkzeug==3.0.6\n",
      "wrapt==1.17.2\n",
      "yarl==1.18.3\n",
      "zipp==3.21.0\n",
      "zstandard==0.23.0\n"
     ]
    }
   ],
   "source": [
    "! pip freeze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websitetext einlesen und f√ºr Embedding vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_website(url):\n",
    "    # read the text from the website\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "\n",
    "    # remove unwanted tags\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    for tag in soup.select(\"nav, footer, .c24-cookie-consent-notice, .ads, .sidebar\"):\n",
    "        tag.decompose()\n",
    "\n",
    "    text = soup.get_text(separator=\"\\n\")  # Extract text while keeping structure\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cookies_info(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    cookies_over = False\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == \"Alle akzeptieren\": #search for end of cookie info which appears at beginning of scraped text\n",
    "            cookies_over = True\n",
    "        if cookies_over:\n",
    "            cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def remove_empty_lines(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def remove_urls(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    skip_next = 0\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if i < len(lines) - 2 and (lines[i+1][0:4] == \"http\" or lines[i+1] == \"hier\" or lines[i+1] == \"Link\" ): # skip urls and remove corresponding line brakes\n",
    "            skip_next = 3\n",
    "            cleaned_lines.append(lines[i] + lines[i+2])\n",
    "        if skip_next > 0:\n",
    "            skip_next -= 1\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "def remove_top_level_headers(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        # Skip first two lines (they only contain headers etc)\n",
    "        if i < 2:\n",
    "            continue\n",
    "\n",
    "        # Detect a top-level section header (e.g., \"3\") followed by a short title\n",
    "        if re.match(r\"^\\d+$\", lines[i].strip()) and i + 1 < len(lines):\n",
    "            continue  # Do not include the number\n",
    "        elif re.match(r\"^\\d+$\", lines[i - 1].strip()):\n",
    "            continue  # Skip title (line after number)\n",
    "\n",
    "        # Add the rest of the content\n",
    "        cleaned_lines.append(lines[i])\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "def propagate_parent_sections(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Propagates parent sections to their respective child sections in a given text.\n",
    "    This function processes a text where sections are denoted by hierarchical numbering (e.g., \"4.2.\", \"4.2.1.\", \"4.2.1.1.\").\n",
    "    It appends the parent section titles to their respective child sections to provide context.\n",
    "    Args:\n",
    "        text (str): The input text containing sections and sub-sections.\n",
    "    Returns:\n",
    "        str: The processed text with parent sections propagated to their child sections.\n",
    "    \"\"\"\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "    current_parent = \"\"\n",
    "    current_child = \"\"\n",
    "    parent_coming = False\n",
    "    child_coming = False\n",
    "    childchild_coming = False\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        if parent_coming:\n",
    "            current_parent = stripped\n",
    "            parent_coming = False\n",
    "\n",
    "        if child_coming:\n",
    "            current_child = stripped\n",
    "            cleaned_lines.append(current_parent + \" \" + line)\n",
    "            child_coming = False\n",
    "        elif childchild_coming:\n",
    "            cleaned_lines.append(current_parent + \" \" + current_child + \" \" + line)\n",
    "            childchild_coming = False\n",
    "        else:\n",
    "            cleaned_lines.append(line)\n",
    "        \n",
    "        # Detect major section (e.g., \"4.2.\") but NOT \"4.2.1.\"\n",
    "        if re.match(r\"^\\d+\\.\\d+\\.$\", stripped):\n",
    "            parent_coming = True\n",
    "        \n",
    "        # Detect sub-sections (e.g., \"4.2.1.\") but not top-level sections\n",
    "        elif re.match(r\"^\\d+\\.\\d+\\.\\d+\\.$\", stripped):\n",
    "            child_coming = True\n",
    "\n",
    "            # Detect sub-sections (e.g., \"4.2.1.\") but not top-level sections\n",
    "        elif re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+\\.$\", stripped):\n",
    "            childchild_coming = True\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "\n",
    "def remove_numbers(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\d+\\.\\d+\\.$\", line) or re.match(r\"^\\d+\\.\\d+\\.\\d+\\.$\", line) or re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+\\.$\", line):\n",
    "            continue\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text from the website\n",
    "text = read_website(website_url)\n",
    "\n",
    "# Preprocess the text by removing unnecessary information and improving formatting\n",
    "text = remove_empty_lines(text)\n",
    "text = remove_cookies_info(text)\n",
    "text = remove_urls(text)\n",
    "text = remove_top_level_headers(text)\n",
    "text = propagate_parent_sections(text)\n",
    "text = remove_numbers(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text in Chunks aufteilen und Embedding-Vectors berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete! Stored 70 chunks in FAISS.\n"
     ]
    }
   ],
   "source": [
    "# Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "# Generate embeddings using OpenAI\n",
    "embeddings = embedding_model.embed_documents(chunks)\n",
    "\n",
    "# Convert to FAISS format with euclidian (L2) distance measure for similarity search\n",
    "dimension = len(embeddings[0])  # Get embedding size\n",
    "faiss_index = faiss.IndexFlatL2(dimension)  # L2 distance\n",
    "faiss_index.add(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "# Store chunk text with same indices as in \n",
    "chunk_metadata = {i: chunks[i] for i in range(len(chunks))}\n",
    "\n",
    "print(\"Vectorization complete! Stored\", len(chunks), \"chunks in FAISS.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F√ºr Prompt relevanteste Chunks heraussuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(query, number_of_chunks_to_retrieve=5):\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "    # Search for similar chunks\n",
    "    _, similar_indices = faiss_index.search(np.array([query_embedding], dtype=np.float32), \n",
    "                                            number_of_chunks_to_retrieve)\n",
    "\n",
    "    # Get the text of the similar chunks\n",
    "    similar_chunks = [chunk_metadata[i] for i in similar_indices[0]]\n",
    "\n",
    "    return similar_chunks, similar_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modell Testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(prompt):\n",
    "    answer = \"\"\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True, \n",
    "    )\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            answer += chunk.choices[0].delta.content\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage:\n",
      " Was kann ich gewinnen?\n",
      "\n",
      "Kontext wird gesucht...\n",
      "\n",
      "Kontext 1:\n",
      "Gutscheine aus der Gesamtwertung und den jeweiligen Spieltagen im Wert von 240 ‚Ç¨ (in Worten zweihundertvierzig) und weniger werden passend zur Gewinneranzahl aufgestockt, damit jeder mit entsprechender Platzierung einen Gutschein erh√§lt.\n",
      "F√ºr die zu gewinnenden Gutscheine gelten die folgenden separaten Gutscheinbedingungen der CHECK24 GmbH ().\n",
      "Ein Anspruch auf Barauszahlung eines Gewinnes (nach Ziffer 4) besteht seitens des Gewinners nicht.\n",
      "Kontext 2:\n",
      "In der Gesamtwertung der CHECK24 Tipprunde vergibt der Veranstalter f√ºr die Nutzer mit den meisten Punkten (gem. Ziffer 2) die folgenden Gewinne:\n",
      "1 x 2.400 ‚Ç¨ Reise-Guthaben\n",
      "Zus√§tzlich gibt es mehrere vom Veranstalter definierte Spieltage. Ein Spieltag bezeichnet einen festgelegten Termin, an dem eine Runde von Spielen innerhalb des Wettbewerbs, wie in der Gruppenphase oder K.-o.-Runde, ausgetragen wird. An einem Spieltag finden mehrere Spiele gleichzeitig statt.\n",
      "Kontext 3:\n",
      "24 x 10 % Hotel- & Ferienwohnungs-Gutschein\n",
      "In der teilnahmeberechtigten Tipprunden (nach der Ziffer 4.2.) vergibt der Veranstalter zudem die folgenden Gewinne:\n",
      "F√ºr die beste Tipprunde, nach der Durchschnittspunktzahl (gem. Ziffer 2) und nach Ende der Ligaphase (29.01.2025) gewertet:\n",
      "11 Tickets f√ºr das Finale der \n",
      "K√∂nigsklasse\n",
      " in M√ºnchen\n",
      "Kontext 4:\n",
      "in M√ºnchen\n",
      "Sollte der Verdacht vorliegen, dass Mitglieder der Tipprunden Ihre Tipps untereinander abgestimmt h√§tten, beh√§lt sich der Betreiber vor, Tipprunden von diesem Preis auszuschlie√üen.\n",
      "F√ºr die jeweiligen Nutzer in den teilnahmeberechtigten Tipprunden mit den meisten Punkten nach Abschluss (gem. Ziffer 2), den ‚ÄûTipprundensiegern‚Äú:\n",
      "2000 x 240 ‚Ç¨ Pauschalreise-Gutscheine (einl√∂sbar ab 2.400 ‚Ç¨ Buchungswert (exkl. lokaler Steuern, wie z.B. Touristensteuer))\n",
      "Kontext 5:\n",
      "Pro Spieltag werden folgende Gewinne f√ºr die Teilnehmer mit den h√∂chsten erreichten Punkten (nach Ziffer 2) der jeweiligen Spieltage vergeben:\n",
      "24 x 240¬†‚Ç¨ Pauschalreise-Gutscheine (einl√∂sbar ab 2.400¬†‚Ç¨ Buchungswert (exkl. lokaler Steuern, wie z.B. Touristensteuer))\n",
      "Pro Spieltag werden folgende Gewinne f√ºr alle Mitglieder der besten teilnahmeberechtigten Tipprunden (nach der Ziffer 4.2.), gemessen nach Durchschnittspunktzahl f√ºr den jeweiligen Spieltag:\n",
      "24 x 10 % Hotel- & Ferienwohnungs-Gutschein\n",
      "\n",
      "Antwort wird generiert...\n",
      "\n",
      "Antwort:\n",
      " Bei dem Gewinnspiel hast du die M√∂glichkeit, folgende Preise zu gewinnen:\n",
      "\n",
      "1. **Gesamtwertung der CHECK24 Tipprunde:**\n",
      "   - 1 x 2.400 ‚Ç¨ Reise-Guthaben f√ºr den Benutzer mit den meisten Punkten.\n",
      "\n",
      "2. **Gewinne pro Spieltag:**\n",
      "   - 24 x 240 ‚Ç¨ Pauschalreise-Gutscheine, einl√∂sbar ab einem Buchungswert von 2.400 ‚Ç¨ (exklusive lokaler Steuern).\n",
      "   - 24 x 10 % Hotel- & Ferienwohnungs-Gutschein.\n",
      "\n",
      "3. **Beste Tipprunde nach der Ligaphase (bis 29.01.2025):**\n",
      "   - 11 Tickets f√ºr das Finale der K√∂nigsklasse in M√ºnchen.\n",
      "\n",
      "4. **Tipprundensieger in den teilnahmeberechtigten Tipprunden:**\n",
      "   - 2.000 x 240 ‚Ç¨ Pauschalreise-Gutscheine, einl√∂sbar ab einem Buchungswert von 2.400 ‚Ç¨ (exklusive lokaler Steuern).\n",
      "\n",
      "Bitte beachte, dass ein Anspruch auf Barauszahlung eines Gewinnes nicht besteht und die Bedingungen des Gewinnspiels beachtet werden m√ºssen.\n"
     ]
    }
   ],
   "source": [
    "# Hier eine Frage zu den Teilnahmebedingungen eingeben um das Modell zu testen\n",
    "query = \"Was kann ich gewinnen?\"\n",
    "\n",
    "\n",
    "\n",
    "print(\"Frage:\\n\", query)\n",
    "\n",
    "\n",
    "# Get context\n",
    "print(\"\\nKontext wird gesucht...\\n\")\n",
    "\n",
    "context_chunks, _ = get_context(query, number_of_chunks_to_retrieve=5)\n",
    "\n",
    "print(\"\\n\".join([\"Kontext \" + str(i + 1) + \":\\n\" + context for i, context in enumerate(context_chunks)]))\n",
    "\n",
    "context = \"\\n\".join(context_chunks) # Combine chunks into one string\n",
    "\n",
    "\n",
    "# Create final prompt\n",
    "print(\"\\nAntwort wird generiert...\\n\")\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Du bist ein KI-Assistent, der Fragen zu den Teilnahmebedingungen eines Gewinnspiels beantwortet. Zur Beantwortung der Frage hast du folgenden Kontext:\n",
    "\n",
    "Kontext:\n",
    "{context}\n",
    "\n",
    "Die Frage des Benutzers lautet:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "answer = get_answer(prompt)\n",
    "\n",
    "print(\"Antwort:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing PCA\n",
      "PCA done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print(\"doing PCA\")\n",
    "pca = PCA(n_components=2)\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "print(\"PCA done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_model(query):\n",
    "    context_chunks, context_indices = get_context(query, number_of_chunks_to_retrieve=5)\n",
    "    context = \"\\n\\n\".join(context_chunks) # Combine chunks into one string\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Du bist ein KI-Assistent, der Fragen zu den Teilnahmebedingungen eines Gewinnspiels beantwortet. Zur Beantwortung der Frage hast du folgenden Kontext:\n",
    "\n",
    "    Kontext:\n",
    "    {context}\n",
    "\n",
    "    Die Frage des Benutzers lautet:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    answer = get_answer(prompt)\n",
    "    return answer, context_indices, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x134545230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "# Update the layout\n",
    "layout = go.Layout(\n",
    "    hovermode='closest',\n",
    "    xaxis={'title': {'text': 'PCA Component 1'}},\n",
    "    yaxis={'title': {'text': 'PCA Component 2'}},\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Create the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"PCA of Text Chunks\", style={\"text-align\": \"center\"}),\n",
    "    \n",
    "    # Text Input for query\n",
    "    html.Div([\n",
    "        dcc.Input(id='query-input', type='text', placeholder='Enter your query here', style={'width': '80%', 'border': '1px solid black'}),\n",
    "        html.Button('Submit', id='submit-button', n_clicks=0)\n",
    "    ], style={'text-align': 'center', 'padding-top': '20px'}),\n",
    "    \n",
    "    # Model Answer\n",
    "    html.Div([\n",
    "        html.H4(\"Model Answer\"),\n",
    "        html.Div(id='model-answer', style={'white-space': 'pre-line', 'padding': '10px'})\n",
    "    ], style={'padding-top': '20px'}),\n",
    "    \n",
    "    # Plot and Text of Selected Chunk\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Graph(\n",
    "                id='scatter-plot',\n",
    "                figure={'data': [trace], 'layout': layout},\n",
    "                config={'displayModeBar': False}  # Turn off the toolbar\n",
    "            ),\n",
    "            html.Div([\n",
    "                html.H4(\"Text of Selected Chunk\"),\n",
    "                html.Div(id='chunk-text', style={'white-space': 'pre-line', 'padding': '10px'})\n",
    "            ], style={'padding-top': '20px'})\n",
    "        ], style={'width': '60%', 'display': 'inline-block', 'vertical-align': 'top', 'padding-top': '5px'}),\n",
    "        \n",
    "        # Augmented Prompt\n",
    "        html.Div([\n",
    "            html.H4(\"Augmented Prompt\"),\n",
    "            html.Div(id='augmented-prompt', style={'white-space': 'pre-line', 'padding': '10px', 'font-size': 'small'})\n",
    "        ], style={'width': '35%', 'display': 'inline-block', 'vertical-align': 'top', 'padding-left': '20px'})\n",
    "    ], style={'padding-top': '5px', 'text-align': 'left'})  # Reduced padding-top here\n",
    "])\n",
    "\n",
    "# Define callback to update the text box when a point is clicked\n",
    "@app.callback(\n",
    "    Output('chunk-text', 'children'),\n",
    "    [Input('scatter-plot', 'clickData')]\n",
    ")\n",
    "def display_chunk_text(clickData):\n",
    "    if clickData is None:\n",
    "        return \"Click on a point to see the chunk text.\"\n",
    "    \n",
    "    # Extract the index of the clicked point\n",
    "    point_index = clickData['points'][0]['pointIndex']\n",
    "    \n",
    "    # Return the text of the corresponding chunk\n",
    "    return chunks[point_index]\n",
    "\n",
    "# Define callback to update the plot with the query embedding, model answer, and augmented prompt\n",
    "@app.callback(\n",
    "    [Output('scatter-plot', 'figure'), Output('model-answer', 'children'), Output('augmented-prompt', 'children')],\n",
    "    [Input('submit-button', 'n_clicks')],\n",
    "    [State('query-input', 'value')]\n",
    ")\n",
    "def update_plot(n_clicks, query):\n",
    "    if n_clicks > 0 and query:\n",
    "        # Get the model answer, context indices, and augmented prompt\n",
    "        model_answer, context_indices, augmented_prompt = prompt_model(query)\n",
    "        \n",
    "        # Create a new trace for the query embedding\n",
    "        query_embedding = embedding_model.embed_query(query)\n",
    "        query_pca = pca.transform([query_embedding])[0]\n",
    "        query_trace = go.Scatter(\n",
    "            x=[query_pca[0]],\n",
    "            y=[query_pca[1]],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color='red', opacity=0.7),\n",
    "            text=[query],  # Add the query text to display on hover\n",
    "            hoverinfo='text',  # Enable hover info\n",
    "            name='Query'  # Add legend name\n",
    "        )\n",
    "        \n",
    "        # Separate the chunks into relevant and non-relevant\n",
    "        relevant_chunks = [i for i in range(len(chunks)) if i in context_indices]\n",
    "        non_relevant_chunks = [i for i in range(len(chunks)) if i not in context_indices]\n",
    "        \n",
    "        # Create traces for relevant and non-relevant chunks\n",
    "        relevant_trace = go.Scatter(\n",
    "            x=pca_embeddings[relevant_chunks, 0],\n",
    "            y=pca_embeddings[relevant_chunks, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color='orange', opacity=0.7),\n",
    "            text=[chunks[i] for i in relevant_chunks],\n",
    "            hoverinfo='none',\n",
    "            name='Relevant Chunks'  # Add legend name\n",
    "        )\n",
    "        \n",
    "        non_relevant_trace = go.Scatter(\n",
    "            x=pca_embeddings[non_relevant_chunks, 0],\n",
    "            y=pca_embeddings[non_relevant_chunks, 1],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color='blue', opacity=0.7),\n",
    "            text=[chunks[i] for i in non_relevant_chunks],\n",
    "            hoverinfo='none',\n",
    "            name='Info-Chunks'  # Add legend name\n",
    "        )\n",
    "        \n",
    "        # Update the figure with the new traces\n",
    "        figure = {\n",
    "            'data': [non_relevant_trace, relevant_trace, query_trace],\n",
    "            'layout': layout\n",
    "        }\n",
    "        \n",
    "        return figure, model_answer, augmented_prompt\n",
    "    \n",
    "    # Return the original figure, empty model answer, and empty augmented prompt if no query is submitted\n",
    "    return {'data': [trace], 'layout': layout}, \"\", \"\"\n",
    "\n",
    "# Run the Dash app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash in ./.venv/lib/python3.13/site-packages (2.18.2)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in ./.venv/lib/python3.13/site-packages (from dash) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in ./.venv/lib/python3.13/site-packages (from dash) (3.0.6)\n",
      "Requirement already satisfied: plotly>=5.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (6.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in ./.venv/lib/python3.13/site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.13/site-packages (from dash) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv/lib/python3.13/site-packages (from dash) (4.12.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from dash) (2.32.3)\n",
      "Requirement already satisfied: retrying in ./.venv/lib/python3.13/site-packages (from dash) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.13/site-packages (from dash) (1.6.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from dash) (75.8.0)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (3.1.5)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./.venv/lib/python3.13/site-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.venv/lib/python3.13/site-packages (from plotly>=5.0.0->dash) (1.25.2)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.13/site-packages (from plotly>=5.0.0->dash) (24.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.13/site-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata->dash) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->dash) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.13/site-packages (from requests->dash) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->dash) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.13/site-packages (from requests->dash) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.7.0 in ./.venv/lib/python3.13/site-packages (from retrying->dash) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install dash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
